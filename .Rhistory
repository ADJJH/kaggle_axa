summary(wines)
boxplot(log(wines[,c(-7)]))
hist(wines$quality)
```
Creating testing and training sets:
```{r}
set.seed(345)
index_wine = sample (1:nrow(wine),round(nrow(wine)*.8),replace = FALSE)
wine.train = wine[index_wine,]
wine.test = wine[-index_wine,]
```
Building regression tree:
```{r}
model_rtree = rpart (quality ~ .,data=wine)
model_rtree
summary(model_rtree)
fancyRpartPlot(model_rtree)
```
Performance:
```{r}
predict_rtree <- predict(model_rtree, wine.test)
summary(predict_rtree)
summary(wine$quality)
cor(predict_rtree, wine.test$quality)
MAE <- function(actual, predicted) {
mean(abs(actual - predicted))
}
MAE(predict_rtree, wine.test$quality)
```
Model tree:
```{r}
model_m5p <- M5P(quality ~ ., data = wine.train)
summary(model_m5p)
model_m5p
```
Performance:
```{r}
predict_m5p = predict(model_m5p,wine.test)
summary(predict_m5p)
summary(wine$quality)
cor(predict_m5p, wine.test$quality)
MAE(predict_m5p, wine.test$quality)
```
Using the model tree the MAE improves from 0.58 to 0.55, and the correlation from 0.54 to 0.58.
###Exercise 2 - Random Forest
```{r}
model_forest = randomForest(quality ~ .,data=wine.train, ntree= 500)
summary(model_forest)
model_forest
model_forest2 = randomForest(quality ~ .,data=wine.train, ntree= 100)
wine = read.csv("R4/Rweek4/whitewines.csv")
set.seed(345)
index_wine = sample (1:nrow(wine),round(nrow(wine)*.8),replace = FALSE)
wine.train = wine[index_wine,]
wine.test = wine[-index_wine,]
model_svm = ksvm(quality ~ ., data=wine, kernel='vanilladot')
predict_svm = predict(model_svm,wine.test)
head(predict_svm)
summary(predict_svm)
summary(wine$quality)
summary(predict_svm[1])
wine = read.csv("R4/Rweek4/whitewines.csv")
set.seed(345)
index_wine = sample (1:nrow(wine),round(nrow(wine)*.8),replace = FALSE)
wine.train = wine[index_wine,]
wine.test = wine[-index_wine,]
model_svm = ksvm(quality ~ ., data=wine, kernel='vanilladot')
predict_svm = predict(model_svm,wine.test)
head(predict_svm)
summary(predict_svm[1])
summary(wine$quality)
summary(predict_svm)
sum(wine$quality == 9)
sum(wine$quality == 8)
cars = read.csv("car.csv")
View(cars)
summary(cars)
dim(cars)
str(cars)
library(ISLR)
library(ggplot2)
library(gridExtra)
library(psych)
library(class)
library(caret)
library(sampling)
library(e1071)
var_list = names(cars)[1:7]
boxplot_list = list()
for (i in 1:6) {
p = ggplot(data=cars,aes_string(x=var_list[[7]], y=var_list[[i]])) +
geom_boxplot() + ggtitle(i)
boxplot_list[[i]] = p
}
grid.arrange(boxplot_list[[1]],boxplot_list[[2]], boxplot_list[[3]], boxplot_list[[4]], boxplot_list[[5]], boxplot_list[[6]], nrow = 2,ncol=3)
var_list = names(cars)[1:7]
boxplot_list = list()
for (i in 1:6) {
p = ggplot(data=cars,aes_string(x=var_list[[7]], y=var_list[[i]])) +
geom_point() + ggtitle(i)
boxplot_list[[i]] = p
}
grid.arrange(boxplot_list[[1]],boxplot_list[[2]], boxplot_list[[3]], boxplot_list[[4]], boxplot_list[[5]], boxplot_list[[6]], nrow = 2,ncol=3)
plot(cars)
mosaicplot(cars)
mosaicplot(cars$Class,cars$Safety)
class.Doors = table(Class,Doors, data=cars)
class.Doors = table(cars$Class,cars$Doors)
class.Doors
mosaicplot(class.Doors, main = "Class - Doors",
class.doors = table(cars$Class,cars$Doors)
mosaicplot(class.doors, main = "Class - Doors",
xlab = "BMI", ylab = "age", cex = 0.75, color = TRUE)
class.doors = table(cars$Class,cars$Doors)
mosaicplot(class.doors, main = "Class - Doors",xlab = "BMI", ylab = "age", cex = 0.75, color = TRUE)
mosaicplot(class.doors, main = "Class - Doors", cex = 0.75, color = TRUE)
mosaicplot(class.doors, main = "Class - Doors",xlab = "Class", ylab = "Doors", cex = 0.75, color = TRUE)
class.buying = table(cars$Class,cars$Buyig)
mosaicplot(class.buying, main = "Class - Doors",xlab = "Class", ylab = "Buying", cex = 0.75, color = TRUE)
class.buying = table(cars$Class,cars$Buying)
mosaicplot(class.buying, main = "Class - Doors",xlab = "Class", ylab = "Buying", cex = 0.75, color = TRUE)
ggplot(Buying,Maint, data = cars fill=Class) + geom_point()
ggplot(Buying,Maint, data = cars, fill=Class) + geom_point()
ggplot(aes(Buying,Maint, data = cars, fill=Class)) + geom_point()
ggplot(aes(Buying,Doors, data = cars, fill=Class)) + geom_point()
library(ISLR)
library(ggplot2)
library(gridExtra)
library(psych)
library(class)
library(caret)
library(sampling)
library(e1071)
class.doors = table(cars$Class,cars$Doors)
mosaicplot(class.doors, main = "Class - Doors",xlab = "Class", ylab = "Doors", cex = 0.75, color = TRUE)
cars = read.csv("car.csv")
mosaicplot(class.doors, main = "Class - Doors",xlab = "Class", ylab = "Doors", cex = 0.75, color = TRUE)
class.doors = table(cars$Class,cars$Doors)
mosaicplot(class.doors, main = "Class - Doors",xlab = "Class", ylab = "Doors", cex = 0.75, color = TRUE)
summary(cars)
ggplot(aes(Buying,Doors, data = cars, fill=Class)) + geom_point()
class.buying = table(cars$Class,cars$Buying)
mosaicplot(class.buying, main = "Class - Doors",xlab = "Class", ylab = "Buying", cex = 0.75, color = TRUE)
class.maint = table(cars$Class,cars$Maint)
mosaicplot(class.maint, main = "Class - Doors",xlab = "Class", ylab = "Maintenance", cex = 0.75, color = TRUE)
with(cars, ftable(Class ~ Maint + Buying))
class.buy.maint = with(cars, ftable(Class ~ Maint + Buying))
mosaicplot(class.buy.maint, main = "Class - Doors",xlab = "Class", ylab = "Maintenance", cex = 0.75, color = Class)
mosaicplot(class.buy.maint, main = "Class - Doors",xlab = "Class", ylab = "Maintenance", cex = 0.75)
plot(cars$Buying,cars(Maint))
plot(cars$Buying,cars$Maint)
plot(cars$Class,cars$Buying)
plot(cars$Class,cars$Buying, xlab="Class",ylab="Buying")
plot(cars$Class,cars$Buying, xlab="Class",ylab="Buying")
p1 = plot(cars$Class,cars$Buying, xlab="Class",ylab="Buying")
p2 = plot(cars$Class,cars$Maint, xlab="Class",ylab="Maint")
p3 = plot(cars$Class,cars$Doors, xlab="Class",ylab="Doors")
p4 = plot(cars$Class,cars$Persons, xlab="Class",ylab="Persons")
p5 = plot(cars$Class,cars$Lung_boot, xlab="Class",ylab="Lung_boot")
p6 = plot(cars$Class,cars$Safety, xlab="Class",ylab="Safety")
grid.arrange(p1,p2,p3,p4,p5,p6, nrow = 2,ncol=3)
grid.arrange(p1,p2,p3,p4,p5,p6, nrow = 2,ncol=3)
p4 = plot(cars$Class,cars$Persons, xlab="Class",ylab="Persons")
p5 = plot(cars$Class,cars$Lung_boot, xlab="Class",ylab="Lung_boot")
cars$Lung_boot
p5 = plot(cars$Class,cars$Lug_boot, xlab="Class",ylab="Lug_boot")
trainIndex <- createDataPartition(cars, p = .7)
head(trainIndex)
cars.train <- cars[ trainIndex,c(1:6)]
cars.test  <- cars[-trainIndex,c(1:6)]
cars.train_labels <- cars[trainIndex, 7]
cars.test_labels <- cars[-trainIndex, 7]
trainIndex <- createDataPartition(cars, p = .7)
head(trainIndex)
trainIndex <- sample(1:nrow(cars), round(nrow(cars)*.7))
head(trainIndex)
set.seed{123}
set.seed(123)
trainIndex <- sample(1:nrow(cars), round(nrow(cars)*.7))
head(trainIndex)
cars.train <- cars[ trainIndex,c(1:6)]
cars.test  <- cars[-trainIndex,c(1:6)]
cars.train_labels <- cars[trainIndex, 7]
cars.test_labels <- cars[-trainIndex, 7]
model_cars_naive = naiveBayes( cars.train[,-7],cars.train_labels)
predict_cars_naive = predict(model_cars_naive,cars.test[,-7] , type= "class")
xtab_cars_naive = table(predict_cars_naive,cars.test_labels)
confusionMatrix(xtab_cars_naive)
model_cars_naive = naiveBayes( cars.train[,c(1,2,6)],cars.train_labels)
predict_cars_naive = predict(model_cars_naive,cars.test[,c(1,2,6)] , type= "class")
xtab_cars_naive = table(predict_cars_naive,cars.test_labels)
confusionMatrix(xtab_cars_naive)
model_cars_naive = naiveBayes( cars.train[,c(1,2,5,6)],cars.train_labels)
predict_cars_naive = predict(model_cars_naive,cars.test[,c(1,2,5,6)] , type= "class")
xtab_cars_naive = table(predict_cars_naive,cars.test_labels)
confusionMatrix(xtab_cars_naive)
model_cars_naive = naiveBayes( cars.train[,c(1,2,3,5,6)],cars.train_labels)
predict_cars_naive = predict(model_cars_naive,cars.test[,c(1,2,3,5,6)] , type= "class")
xtab_cars_naive = table(predict_cars_naive,cars.test_labels)
confusionMatrix(xtab_cars_naive)
model_cars_naive = naiveBayes( cars.train[,c(1,2,3,4,5,6)],cars.train_labels)
predict_cars_naive = predict(model_cars_naive,cars.test[,c(1,2,3,4,5,6)] , type= "class")
xtab_cars_naive = table(predict_cars_naive,cars.test_labels)
confusionMatrix(xtab_cars_naive)
model_cars_naive = naiveBayes( cars.train[,c(1,2,4,5,6)],cars.train_labels)
predict_cars_naive = predict(model_cars_naive,cars.test[,c(1,2,4,5,6)] , type= "class")
xtab_cars_naive = table(predict_cars_naive,cars.test_labels)
confusionMatrix(xtab_cars_naive)
model_cars_naive = naiveBayes( cars.train[,c(1,2,4,5,6)],cars.train_labels,laplace =1)
predict_cars_naive = predict(model_cars_naive,cars.test[,c(1,2,4,5,6)] , type= "class")
xtab_cars_naive = table(predict_cars_naive,cars.test_labels)
confusionMatrix(xtab_cars_naive)
model_cars_naive = naiveBayes( cars.train[,c(1,2,4,5,6)],cars.train_labels,laplace =2)
predict_cars_naive = predict(model_cars_naive,cars.test[,c(1,2,4,5,6)] , type= "class")
xtab_cars_naive = table(predict_cars_naive,cars.test_labels)
confusionMatrix(xtab_cars_naive)
model_cars_naive = naiveBayes( cars.train[,c(1,2,4,5,6)],cars.train_labels,laplace = 3)
predict_cars_naive = predict(model_cars_naive,cars.test[,c(1,2,4,5,6)] , type= "class")
xtab_cars_naive = table(predict_cars_naive,cars.test_labels)
confusionMatrix(xtab_cars_naive)
model_cars_naive = naiveBayes( cars.train[,c(1,2,4,5,6)],cars.train_labels,laplace = 0)
predict_cars_naive = predict(model_cars_naive,cars.test[,c(1,2,4,5,6)] , type= "class")
xtab_cars_naive = table(predict_cars_naive,cars.test_labels)
confusionMatrix(xtab_cars_naive)
library (ggplot2)
library(rpart)
library(rattle) #for tree visualization
library(RWeka) #for model tree
library(randomForest)
library(caret)
library(kernlab)
wine = read.csv("R4/Rweek4/whitewines.csv")
summary(wines)
boxplot(log(wines[,c(-7)]))
hist(wines$quality)
wine = read.csv("R4/Rweek4/whitewines.csv")
#wine$quality = as.factor(wine$quality)
```
Exporing data:
```{r}
summary(wine)
boxplot(log(wine[,c(-7)]))
hist(wine$quality)
```
hist(wine$quality)
model_rtree = rpart (quality ~ .,data=wine)
model_rtree
summary(model_rtree)
set.seed(345)
index_wine = sample (1:nrow(wine),round(nrow(wine)*.8),replace = FALSE)
wine.train = wine[index_wine,]
wine.test = wine[-index_wine,]
model_rtree = rpart (quality ~ .,data=wine)
model_rtree
summary(model_rtree)
fancyRpartPlot(model_rtree)
summary(model_rtree)
predict_rtree <- predict(model_rtree, wine.test)
summary(predict_rtree)
summary(wine$quality)
cor(predict_rtree, wine.test$quality)
MAE <- function(actual, predicted) {
mean(abs(actual - predicted))
}
MAE(predict_rtree, wine.test$quality)
model_rtree = rpart (quality ~ .,data=wine)
model_rtree
summary(model_rtree)
fancyRpartPlot(model_rtree)
summarymodel_svm
summary(model_svm)
shiny::runApp('Shiny Project/Prohect-Shiny')
shiny::runApp('Shiny Project/Prohect-Shiny')
shiny::runApp('Shiny Project/Prohect-Shiny')
shiny::runApp('Shiny Project/Prohect-Shiny')
shiny::runApp('Shiny Project/Prohect-Shiny')
shiny::runApp('Shiny Project/Prohect-Shiny')
shiny::runApp('Shiny Project/Prohect-Shiny')
shiny::runApp('Shiny Project/Prohect-Shiny')
shiny::runApp('Shiny Project/Prohect-Shiny')
shiny::runApp('Shiny Project/Prohect-Shiny')
shiny::runApp('Shiny Project/Prohect-Shiny')
shiny::runApp('Shiny Project/Prohect-Shiny')
shiny::runApp('Shiny Project/Prohect-Shiny')
shiny::runApp('Shiny Project/Prohect-Shiny')
shiny::runApp('Shiny Project/Prohect-Shiny')
shiny::runApp('Shiny Project/Prohect-Shiny')
shiny::runApp('Shiny Project/Prohect-Shiny')
shiny::runApp('Shiny Project/Prohect-Shiny')
shiny::runApp('Shiny Project/Prohect-Shiny')
load("Data/small_axa.RData")
setwd("~/BC files/R ex/Kaggle/kaggle_axa")
load("Data/small_axa.RData")
dim(axa) #600 Observations, 88 Variables
names(axa)
sapply(axa, class)
table(sapply(axa, class)) #Characters need to be converted to numeric type.
###Converting character variables to numeric variables.
converted.columns = sapply(axa[, 2:87], as.numeric)
axa.converted = data.frame(axa[, 1], converted.columns, axa[, 88])
names(axa.converted) = names(axa)
axa.converted$driver = as.factor(substr(axa.converted$driver_trip, 1, 1))
names <- names(axa.converted)
names <- gsub("-", "_", names)
names(axa.converted) <- names
remove(axa)
axa = axa.converted
remove(axa.converted)
View(axa)
axa = axa[,-c(1,74:79,90)]
set.seed(345)
index_axa = sample (1:nrow(axa),round(nrow(axa)*.8),replace = FALSE)
axa.train = wine[index_axa,]
axa.test = wine[-index_axa,]
model_rtree = rpart (isDriver ~ .,data=axa)
library (ggplot2)
library(rpart)
library(rattle)
model_rtree = rpart (isDriver ~ .,data=axa)
fancyRpartPlot(model_rtree)
model_rtree
summary(model_rtree)
axa.test = axa[-index_axa,]
axa = axa[,-c(1,74:79,90)]
set.seed(345)
index_axa = sample (1:nrow(axa),round(nrow(axa)*.8),replace = FALSE)
axa.train = axa[index_axa,]
axa.test = axa[-index_axa,]
model_rtree = rpart (isDriver ~ .,data=axa)
fancyRpartPlot(model_rtree)
summary(model_tree)
summary(model_rtree)
model_rtree
axa.new = axa[, -c(1, 74:79, 90)]
axa.knn = kNN(axa.new)
axa.imputed = axa.knn[, 1:82]
load("Data/small_axa.RData")
converted.columns = sapply(axa[, 2:87], as.numeric)
axa.converted = data.frame(axa[, 1], converted.columns, axa[, 88])
names(axa.converted) = names(axa)
axa.converted$driver = as.factor(substr(axa.converted$driver_trip, 1, 1))
names <- names(axa.converted)
names <- gsub("-", "_", names)
names(axa.converted) <- names
remove(axa)
axa = axa.converted
remove(axa.converted)
axa.new = axa[, -c(1, 74:79, 90)]
axa.knn = kNN(axa.new)
library(VIM)
axa.knn = kNN(axa.new)
axa.imputed = axa.knn[, 1:82]
set.seed(345)
index_axa = sample (1:nrow(axa.imputed),round(nrow(axa.imputed)*.8),replace = FALSE)
axa.train = axa.imputed[index_axa,]
axa.test = axa.imputed[-index_axa,]
library (caret)
index_axa = sample (1:nrow(axa.imputed),round(nrow(axa.imputed)*.8),replace = FALSE)
axa.train = axa.imputed[index_axa,]
axa.test = axa.imputed[-index_axa,]
rf_model<-train(isDriver ~.,data=axa.Train,method="rf",
trControl=trainControl(method="cv",number=5),
prox=TRUE,allowParallel=TRUE)
index_axa = sample (1:nrow(axa.imputed),round(nrow(axa.imputed)*.8),replace = FALSE)
axa.train = axa.imputed[index_axa,]
axa.test = axa.imputed[-index_axa,]
rf_model<-train(isDriver ~.,data=axa.train,method="rf",
trControl=trainControl(method="cv",number=5),
prox=TRUE,allowParallel=TRUE)
rf_model<-train(isDriver ~.,data=axa.train,method="rf",
trControl=trainControl(method="cv",number=5),
prox=TRUE,allowParallel=TRUE)
rf_model<-train(isDriver ~ .,data=axa.train,method="rf", trControl=trainControl(method="cv",number=5), prox=TRUE,allowParallel=TRUE)
rf_model<-train(isDriver ~ .,data=axa.train,method="rf", trControl=trainControl(method="cv",number=5))
View(axa.train)
rf_model<-train(isDriver ~ .,data=axa.train[,-"isDriver"],method="rf", trControl=trainControl(method="cv",number=5))
rf_model<-train(isDriver ~ .,data=axa.train[,-c("isDriver")],method="rf", trControl=trainControl(method="cv",number=5))
axa.train[,-'isDriver']
axa.train[,!"isDriver"]
axa.train[,"isDriver"]
axa.train[,-"isDriver"]
axa.train[,-c("isDriver")]
axa.train[,"isDriver"]
axa.train[,-"isDriver"]
axa.train[-"isDriver"]
axa.train[,-which(names(axa.train) == "isDriver")]
rf_model<-train(isDriver ~ .,
data=axa.train[,-which(names(axa.train) == "isDriver")],
method="rf", trControl=trainControl(method="cv",number=5))
View(axa.train)
data=axa.train,
set.seed(998)
inTraining <- createDataPartition(axa.imputed$isDriver, p = .75, list = FALSE)
View(inTraining)
inTraining <- createDataPartition(axa.imputed, p = .75, list = FALSE)
set.seed(998)
inTraining <- createDataPartition(axa.imputed$isDriver, p = .75, list = FALSE)
training <- axa.imputed[ inTraining,]
testing  <- axa.imputed[-inTraining,]
rf_model<-train(isDriver ~ .,
data=training,
method="rf", trControl=trainControl(method="cv",number=5))
rf_model<-train(isDriver ~ axa.imputed[-81],
data=training,
method="rf", trControl=trainControl(method="cv",number=5))
rf_model<-train(isDriver ~ axa.imputed[,-81],
data=training,
method="rf", trControl=trainControl(method="cv",number=5))
rf_model<-train(isDriver ~ training[,-81],
data=training,
method="rf", trControl=trainControl(method="cv",number=5))
axa.imputed$isDriver = as.factor(axa.imputed$isDriver)
set.seed(998)
inTraining <- createDataPartition(axa.imputed$isDriver, p = .75, list = FALSE)
training <- axa.imputed[ inTraining,]
testing  <- axa.imputed[-inTraining,]
rf_model<-train(isDriver ~ . ,
data=training,
method="rf", trControl=trainControl(method="cv",number=5))
print(rf_model)
esult.predicted.prob <- predict(rf_model, testing, type="prob")
result.predicted.prob <- predict(rf_model, testing, type="prob")
print(rf_model)
result.predicted.prob <- predict(rf_model, testing, type="prob") # Prediction
rf_model<-train(isDriver ~ . ,
data=training,
method="rf", trControl=trainControl(method="cv",number=5),
metric = "ROC")
rf_model<-train(isDriver ~ . ,
data=training,
method="rf",
metric = "ROC")
rf_model<-train(isDriver ~ . ,
data=training,
method="rf")
result.predicted.prob <- predict(rf_model, testing, type="prob") # Prediction
model_svm = ksvm(quality ~ ., data=wine, kernel='vanilladot')
predict_svm = predict(model_svm,wine.test)
head(predict_svm)
summary(predict_svm)
wine = read.csv("R4/Rweek4/whitewines.csv")
result.predicted.prob <- predict(rf_model, testing, type="prob") # Prediction
rf.model2 <-randomForest(isDriver ~.,data= training, mtry=2, ntree=100,
keep.forest=TRUE, importance=TRUE,test=testing)
result.predicted.prob <- predict(rf.model2, new_data = testing, type="prob") # Prediction
result.predicted.prob
result.predicted.prob <- predict(rf.model2, new_data = testing, type="prob") # Prediction
colnames(result.predicted.prob) <- c("not_driver","driver")
head(result.predicted.prob )
result.roc <- roc(testing$isDriver, result.predicted.prob$driver) # Draw ROC curve.
rf.pred = prediction(predicted.prob, testing$isDriver)
library(ROCR)
install.packages("ROCR")
library(ROCR)
rf.pred = prediction(predicted.prob, testing$isDriver)
predicted.prob <- predict(rf.model2, new_data = testing, type="prob") # Prediction
colnames(predicted.prob) <- c("not_driver","driver")
rf.pred = prediction(predicted.prob, testing$isDriver)
install.packages("pROC")
library(pROC)
result.roc <- roc(testing$isDriver, result.predicted.prob$driver) # Draw ROC curve.
result.roc <- roc(testing$isDriver, predicted.prob$driver) # Draw ROC curve.
predicted.prob
class(predicted.prob )
rf_model<-train(isDriver ~ . ,
data=training,
method="rf"),
trControl=trainControl(method="cv",number=5))#
rf_model<-train(isDriver ~ . ,
data=training,
method="rf",
trControl=trainControl(method="cv",number=5))
rf_model
predicted.prob <- predict(rf.model, new_data = testing, type="prob") # Prediction
predicted.prob <- predict(rf_model, new_data = testing, type="prob") # Prediction
predicted.prob <- predict(rf_model, new_data = testing, type="prob") # Prediction
predicted.prob <- predict(rf_model, new_data = testing, type="prob") # Prediction
training
rf_model<-train(isDriver ~ . ,
data=training,
method="rf",
trControl=trainControl(method="cv",number=5))
rf_model
predicted.prob <- predict(rf_model, new_data = testing[,-81], type="prob") # Prediction
class(rf_model)
predicted.prob <- predict(rf_model, new_data = testing, type="prob") # Prediction
head(test)
head(testing)
class(testieng)
class(testi\ng)
class(testing)
View(testing)
predicted.prob <- predict(rf_model, new_data = testing, type="prob") # Prediction
predicted.prob <- predict(rf_model,  testing, type="prob") # Prediction
predicted.prob <- predict(rf_model,testing, type="prob") # Prediction
rf.model2
rf.model2
summary(rf_model2)
set.seed(1)
data(iris)
iris.rf <- randomForest(Species ~ ., iris, proximity=TRUE,
keep.forest=FALSE)
MDSplot(iris.rf, iris$Species)
rf.model2 <-randomForest(isDriver ~.,data= training, mtry=2, ntree=100,
keep.forest=TRUE, importance=TRUE,test=testing)
predicted.prob <- predict(rf_model,testing, type="prob") # Prediction
predicted.prob <- predict(rf.model2,testing, type="prob") # Prediction
predicted.prob
predicted.prob <- predict(rf.model2,testing, type="class") # Prediction
predicted.prob
colnames(predicted.prob) <- c("not_driver","driver")
predicted.prob <- predict(rf.model2,testing, type="prob") # Prediction
